%Chapter 5
\chapter{Conclusion}
\label{Chapter5}
In this thesis I proposed that the no free lunch hypotheis might not apply to
meta learning algorithms. In order to test this hypothesis, I first built a
system to determine the accuracy of three meta learning strategies:
Exhaustive, Active, and Sampling. To use these strategies, a base of
datasets would first be randomly choosen from the collection of all available
datasets that had been gathered from the UCI Irvine data repository.
Each strategy would then be carried out on the metabase and make an
estimate as to what algorithm would result in the highest classification
accuracy. Each algorithm would make this guess for each dataset in the
collection of available datasets excluding the datasets within the current
metabase. A new metabase would then be choosen at random and the process would
repeated 9 more times, giving a number between 0 and 10 for how many times
each algorithm got the First, second, or third most correct guesses.
This process was repeated 30 times, resulting in 30 samples. $t$ test analysis
was then performed, giving an an average among the absolute values of each of
the position $t$ scores of 5.11, allowing us to reject the null
hypothesis at a 5 percent margin of error.

A flaw exist within this experiment that I would correct had I more time: I was
only able to obtain one set of datasets with 88 instances in it. As such there
is a possibility of bias in the data. This potential of bias can be mitigated
with the introduction of extra sets of datasets, with the ideal being a unique
set of datasets for each sample, but I unfortunately do not currently have the
time to obtain and transform any more data.
