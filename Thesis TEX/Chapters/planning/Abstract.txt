A comparison of metalearning strategies

Determining what algorithm to use when analyzing a dataset is a problem as old as machine learning itself. In some cases, the
individuals wishing to perform an analysis have access to an expert that can simply tell them which algorithm is best in the
given situation. In other situations, the individuals wishing to perform analysis may not have the budget neccessary to 
acquire access to such an export, in which case the usage of a metalearner becomes appropriate. With a metalearner one feeds 
the metalearner a dataset and it returns to the user what it thinks is the most appropriate machine with which to perform
analysis. To get to the point wherein a decision can be made on new datasets the metalearner itself must first be trained, 
and this training itself requires some sort of learning strategy. The comparison of the learning strategies used to train a
metalearner will be the central focus of this project. 
The act of utilizing a metalearning strategy generally involves the following activities: one must take a set of datasets, 
get a measure of how well those datasets perform with a given body of algorithms then use the information contained within 
this "metabase" to run an algorithm that will then spit out a resulting machine for consideration. Here in lies the meat of 
the work that must be done to accomplish my stated goal. The system that I will build will first iterate thru the set of 
learning strategies to be compared, building metabases for each of them and recording how long it took to build each of 
these metabases. It will then take a set of test datasets and have machines spit out for each of these datasets, with the 
resulting choice being recorded as the choices are made. A time of traing/accuracy analysis will then be performed between 
the different learning strategies 


Candidate metalearning algorithms: 
1. Active metalearning (Ranking of classifiers based on dataset charactersitics using active meta learning)
2. A generic clustering algorithms
3. Sampling strategy outlined in (Predicting relative performance of classifiers from samples)