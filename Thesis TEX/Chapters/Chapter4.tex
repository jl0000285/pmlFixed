%Chapter 4
\chapter{Research Findings}
\label{Chapter4}
\section{Run Results and Analysis Tools}
If the no free lunch theorem applies to  meta-learning strategies, we
should see near equal performance across a variety of meta-set collections.
We will call this assertion the null hypothesis, that is to say our null
hypothesis is that the meta-learning strategies used in this experiment
are equal.

In order to test the null hypothesis, 30 such samples of the kind described
in Chapter 3 were collected. The metrics of interest on these samples are
contained in the tables within this chapter. How often the algorithms placed
first, second, or third can be seen in table 4.1. The average of these
placements across all samples, i.e the algorithms average placements, can be
seen in table 4.2. Table 4.3 contains the proportion of probability for the
results contained in table 4.1. Table 4.4 contains the average of the
proportion of probabilities contained in table 4.3 across all samples.
Table 4.5 contains the standard deviations of the placement values for the
meta-algorithms. Table 4.6 contains the t scores of each of the values present
in table 4.1. Table 4.7 contains the average of the t scores contained in
table 4.6 across all samples and it is this table that I use later to draw the
conclusion that the null hypothesis may be safely rejected.

\begin{table}
\begin{tabular}{lrrrrrrrrr}
\toprule

     & \multicolumn{3}{c} {GuessesActive}  & \multicolumn{3}{c}{GuessesEx}  & \multicolumn{3}{c}{GuessesSamp}  \\
     &   First &  Second &  Third &         First &  Second  &  Third &           First &  Second &  Third \\
\midrule
sample 1   &             1 &  4 &  5 &         6 &  2 &  2 &           3 &  4 &  3 \\
sample 2   &             1 &  4 &  5 &         5 &  2 &  3 &           4 &  4 &  2 \\
sample 3   &             1 &  3 &  6 &         7 &  3 &  0 &           2 &  4 &  4 \\
sample 4   &             1 &  5 &  4 &         6 &  3 &  1 &           3 &  2 &  5 \\
sample 5   &             0 &  6 &  4 &         8 &  2 &  0 &           2 &  2 &  6 \\
sample 6   &             3 &  3 &  4 &         5 &  4 &  1 &           2 &  3 &  5 \\
sample 7   &             4 &  3 &  3 &         4 &  4 &  2 &           2 &  3 &  5 \\
sample 8   &             2 &  3 &  5 &         7 &  2 &  1 &           1 &  5 &  4 \\
sample 9   &             1 &  3 &  6 &         3 &  5 &  2 &           6 &  2 &  2 \\
sample 10  &             0 &  4 &  6 &         7 &  3 &  0 &           3 &  3 &  4 \\
sample 11  &             0 &  6 &  4 &         7 &  3 &  0 &           3 &  1 &  6 \\
sample 12 &             1 &  5 &  4 &         7 &  2 &  1 &           2 &  3 &  5 \\
sample 13 &             3 &  3 &  4 &         5 &  4 &  1 &           2 &  3 &  5 \\
sample 14 &             2 &  5 &  3 &         6 &  3 &  1 &           2 &  2 &  6 \\
sample 15 &             2 &  1 &  7 &         4 &  6 &  0 &           4 &  3 &  3 \\
sample 16 &             1 &  5 &  4 &         6 &  0 &  4 &           3 &  5 &  2 \\
sample 17 &             1 &  4 &  5 &         6 &  4 &  0 &           3 &  2 &  5 \\
sample 18 &             1 &  3 &  6 &         8 &  1 &  1 &           1 &  6 &  3 \\
sample 19 &             1 &  4 &  5 &         7 &  3 &  0 &           2 &  3 &  5 \\
sample 20 &             2 &  4 &  4 &         6 &  2 &  2 &           2 &  4 &  4 \\
sample 21 &             1 &  2 &  7 &         4 &  6 &  0 &           5 &  2 &  3 \\
sample 22 &             3 &  3 &  4 &         2 &  7 &  1 &           5 &  0 &  5 \\
sample 23 &             3 &  4 &  3 &         6 &  4 &  0 &           1 &  2 &  7 \\
sample 24 &             3 &  3 &  4 &         4 &  4 &  2 &           3 &  3 &  4 \\
sample 25 &             2 &  6 &  2 &         7 &  3 &  0 &           1 &  1 &  8 \\
sample 26 &             1 &  3 &  6 &         6 &  2 &  2 &           3 &  5 &  2 \\
sample 27 &             7 &  2 &  1 &         3 &  5 &  2 &           0 &  3 &  7 \\
sample 28 &             0 &  5 &  5 &         7 &  2 &  1 &           3 &  3 &  4 \\
sample 29 &             1 &  2 &  7 &         4 &  5 &  1 &           5 &  3 &  2 \\
sample 30 &             2 &  6 &  2 &         4 &  3 &  3 &           4 &  1 &  5 \\
\bottomrule
\end{tabular}
\caption{Placement results}
\end{table}


\begin{table}
\begin{tabular}{lrrr}
\toprule
{} &  GuessesActive &  GuessesEx &  GuessesSamp \\
\midrule
First  &           1.70 &        3.8 &         4.50 \\
Second &           5.57 &        3.3 &         1.13 \\
Third  &           2.73 &        2.9 &         4.37 \\
\bottomrule
\end{tabular}
\caption{Average placement results across all samples}
\end{table}

Each of the meta-set collections contains 10 basesets and the experiment
compares the performance of 3 meta-learning algorithms. As such, the expected
average number of first, second, and third place finishes given that the
meta-learning algorithms are equal is 3.3. The values seen within the placement
counts table given equal meta-learning algorithms should more often than not be
either 3 or 4 and the averages of the placements across all samples should all
be near 3.3. Instead, it appears that the sampler performed the best,
with an average number of first place finshes of 4.5. Moreover most of the
averages present in table 4.2 seem to be farther away from the expected value of
3.3 than one would intuitively expect if the meta-learning algorithms were
truly equal. Whether or not these results fall far enough outside
expectation in order to reject the null hypothesis requires analysis with the
machinary of classical statistics. Two well established hypothesis testing
measures are the method of calculating sampling distribution probabilities and
t score analysis. A brief description of each of these statistical methods
follows.

\subsection{Exact Sampling Distribution}
The following description losely follows the procedure described in \cite{Cohen}.
In it, the author asks the reader to imagine testing a coin to see whether or
not it is fair, flipping the coin 1,2,..N times. He then asks the reader to
consider whether some proportion of heads is actually fair from 0/N, 1/N.., N/N
heads. The propability that some proportion of heads p = i/N is fair can be
calculated exactly with the binomial distribution
$$\frac{N!}{i!(N-i)!}r^{i}(1-r)^{N-i}$$
This situation is analogous to the number of first, second, or third place
finishes some meta-algorithm obtained in this thesis experiment. The probabilty
of proportions for each of the meta-learning algorithms can be seen in table 4.3
and the average of these proportions across all samples can be seen in table 4.4.

\begin{table}
\begin{tabular}{lrrrrrrrrr}
\toprule
 & \multicolumn{3}{l}{GuessesActive} & \multicolumn{3}{l}{GuessesEx} & \multicolumn{3}{l}{GuessesSamp} \\
 &             First &     Second &     Third &   First &     Second &     Third &     First &     Second &  Third \\
\midrule
sample 1  &          0.09 &  0.23 &  0.14 &      0.06 &  0.20 &  0.20 &        0.26 &  0.23 &  0.26 \\
sample 2  &          0.09 &  0.23 &  0.14 &      0.14 &  0.20 &  0.26 &        0.23 &  0.23 &  0.20 \\
sample 3  &          0.09 &  0.26 &  0.06 &      0.02 &  0.26 &  0.02 &        0.20 &  0.23 &  0.23 \\
sample 4  &          0.09 &  0.14 &  0.23 &      0.06 &  0.26 &  0.09 &        0.26 &  0.20 &  0.14 \\
sample 5  &          0.02 &  0.06 &  0.23 &      0.00 &  0.20 &  0.02 &        0.20 &  0.20 &  0.06 \\
sample 6  &          0.26 &  0.26 &  0.23 &      0.14 &  0.23 &  0.09 &        0.20 &  0.26 &  0.14 \\
sample 7  &          0.23 &  0.26 &  0.26 &      0.23 &  0.23 &  0.20 &        0.20 &  0.26 &  0.14 \\
sample 8  &          0.20 &  0.26 &  0.14 &      0.02 &  0.20 &  0.09 &        0.09 &  0.14 &  0.23 \\
sample 9  &          0.09 &  0.26 &  0.06 &      0.26 &  0.14 &  0.20 &        0.06 &  0.20 &  0.20 \\
sample 10 &          0.02 &  0.23 &  0.06 &      0.02 &  0.26 &  0.02 &        0.26 &  0.26 &  0.23 \\
sample 11 &          0.02 &  0.06 &  0.23 &      0.02 &  0.26 &  0.02 &        0.26 &  0.09 &  0.06 \\
sample 12 &          0.09 &  0.14 &  0.23 &      0.02 &  0.20 &  0.09 &        0.20 &  0.26 &  0.14 \\
sample 13 &          0.26 &  0.26 &  0.23 &      0.14 &  0.23 &  0.09 &        0.20 &  0.26 &  0.14 \\
sample 14 &          0.20 &  0.14 &  0.26 &      0.06 &  0.26 &  0.09 &        0.20 &  0.20 &  0.06 \\
sample 15 &          0.20 &  0.09 &  0.02 &      0.23 &  0.06 &  0.02 &        0.23 &  0.26 &  0.26 \\
sample 16 &          0.09 &  0.14 &  0.23 &      0.06 &  0.02 &  0.23 &        0.26 &  0.14 &  0.20 \\
sample 17 &          0.09 &  0.23 &  0.14 &      0.06 &  0.23 &  0.02 &        0.26 &  0.20 &  0.14 \\
sample 18 &          0.09 &  0.26 &  0.06 &      0.00 &  0.09 &  0.09 &        0.09 &  0.06 &  0.26 \\
sample 19 &          0.09 &  0.23 &  0.14 &      0.02 &  0.26 &  0.02 &        0.20 &  0.26 &  0.14 \\
sample 20 &          0.20 &  0.23 &  0.23 &      0.06 &  0.20 &  0.20 &        0.20 &  0.23 &  0.23 \\
sample 21 &          0.09 &  0.20 &  0.02 &      0.23 &  0.06 &  0.02 &        0.14 &  0.20 &  0.26 \\
sample 22 &          0.26 &  0.26 &  0.23 &      0.20 &  0.02 &  0.09 &        0.14 &  0.02 &  0.14 \\
sample 23 &          0.26 &  0.23 &  0.26 &      0.06 &  0.23 &  0.02 &        0.09 &  0.20 &  0.02 \\
sample 24 &          0.26 &  0.26 &  0.23 &      0.23 &  0.23 &  0.20 &        0.26 &  0.26 &  0.23 \\
sample 25 &          0.20 &  0.06 &  0.20 &      0.02 &  0.26 &  0.02 &        0.09 &  0.09 &  0.00 \\
sample 26 &          0.09 &  0.26 &  0.06 &      0.06 &  0.20 &  0.20 &        0.26 &  0.14 &  0.20 \\
sample 27 &          0.02 &  0.20 &  0.09 &      0.26 &  0.14 &  0.20 &        0.02 &  0.26 &  0.02 \\
sample 28 &          0.02 &  0.14 &  0.14 &      0.02 &  0.20 &  0.09 &        0.26 &  0.26 &  0.23 \\
sample 29 &          0.09 &  0.20 &  0.02 &      0.23 &  0.14 &  0.09 &        0.14 &  0.26 &  0.20 \\
sample 30 &          0.20 &  0.06 &  0.20 &      0.23 &  0.26 &  0.26 &        0.23 &  0.09 &  0.14 \\
\bottomrule
\end{tabular}
\caption{Placement results proportion probabilities}
\end{table}


\begin{table}
\begin{tabular}{lrrr}
\toprule
{} &  GuessesActive &  GuessesEx &  GuessesSamp \\
\midrule
First  &        0.13 &       0.19 &         0.16 \\
Second &        0.10 &       0.19 &         0.11 \\
Third  &        0.19 &       0.20 &         0.16 \\
\bottomrule
\end{tabular}
\caption{Average of proportion probabilities across all samples}
\end{table}

We can calculate the probability of drawing either of the values closest
to expectation, 3 or 4, by use of the previously mentioned binomial distribution,
with $N = 10$, $r = 0.33$, and $i$ being either 3 or 4. The values we get for
the propabilities of the most expected values are then 0.26 and 0.22
respectively. The average of all values within this table is
0.15, significantly lower than the probability of the expected value.
Still, this is not enough to reject the null hypothesis as proportion
probability analysis does not come with a rejection criteria.

\subsection{t score}
$t$ score analysis is a form of hypothesis testing that allows one to determine
whether or not some result emerged from some given distribution via consideration
of how many standard deviations the result deviates from the mean of said given
distribution. Its equation has the form:
$$t =\frac{\overline{x}-\mu}{\hat{\sigma}_{\overline{x}}} = \frac{\overline{x}-\mu}{\frac{s}{\sqrt{N}}}$$
where $s$ is the sample standard deviation, $N$ is the number of samples,
$\overline{x}$ is an individual samples mean/calculated value, and $\mu$ is
the mean of the distribution of comparison.

The decision as to whether or not a specific $t$ score value implies a result
is from a different distribution depends on how many samples were used in the
calculation of the sample mean and on what the desired confidence interval is.
The critical threshold used in order to make this decision is gained by the use
of $t$ distribution table. In the case where 30 samples are used and the desired
margin of error is 5\%, the critical thresholds for a two tailed $t$ test are
-2.042 and 2.042. If the averaged values of the $t$ scores falls outside of
these bounds then we can reject the null hypothesis with a 5 \% margin of error.
The standard deviations and $t$ scores for each of the samples can be seen in
table 4.4. Taking the average of the absolute value of each of these $t$ scores
yeilds 5.11. We can thus comfortably reject the null hypothesis.


\begin{table}
\begin{tabular}{lrrr}
\toprule
{} &  GuessesActive &  GuessesEx &  GuessesSamp \\
\midrule
First  &           1.42 &       1.30 &     1.48 \\
Second &           1.54 &       1.53 &     1.06 \\
Third  &           1.36 &       1.33 &     1.58 \\
\bottomrule
\end{tabular}
\caption{Placement results standard deviations across all samples}
\end{table}


\begin{table}
\begin{tabular}{lrrrrrrrrr}
\toprule
algorithms & \multicolumn{3}{l}{GuessesActive} & \multicolumn{3}{l}{GuessesEx} & \multicolumn{3}{l}{GuessesSamp} \\
positions &  First &   Second &    Third &    First &  Second &  Third &    First &  Second &  Third \\
\midrule
sample 1  &        -10.41 &   3.24 &   7.13 &     10.93 &  -5.51 &  -7.98 &       -1.54 &   3.18 &  -1.33 \\
sample 2  &        -10.41 &   3.24 &   7.13 &      6.83 &  -5.51 &  -2.00 &        3.09 &   3.18 &  -5.33 \\
sample 3  &        -10.41 &  -1.62 &  11.41 &     15.04 &  -1.38 & -19.96 &       -6.18 &   3.18 &   2.67 \\
sample 4  &        -10.41 &   8.10 &   2.85 &     10.93 &  -1.38 & -13.97 &       -1.54 &  -6.36 &   6.67 \\
sample 5  &        -14.87 &  12.96 &   2.85 &     19.14 &  -5.51 & -19.96 &       -6.18 &  -6.36 &  10.67 \\
sample 6  &         -1.49 &  -1.62 &   2.85 &      6.83 &   2.75 & -13.97 &       -6.18 &  -1.59 &   6.67 \\
sample 7  &          2.97 &  -1.62 &  -1.43 &      2.73 &   2.75 &  -7.98 &       -6.18 &  -1.59 &   6.67 \\
sample 8  &         -5.95 &  -1.62 &   7.13 &     15.04 &  -5.51 & -13.97 &      -10.81 &   7.95 &   2.67 \\
sample 9  &        -10.41 &  -1.62 &  11.41 &     -1.37 &   6.89 &  -7.98 &       12.36 &  -6.36 &  -5.33 \\
sample 10 &        -14.87 &   3.24 &  11.41 &     15.04 &  -1.38 & -19.96 &       -1.54 &  -1.59 &   2.67 \\
sample 11 &        -14.87 &  12.96 &   2.85 &     15.04 &  -1.38 & -19.96 &       -1.54 & -11.13 &  10.67 \\
sample 12 &        -10.41 &   8.10 &   2.85 &     15.04 &  -5.51 & -13.97 &       -6.18 &  -1.59 &   6.67 \\
sample 13 &         -1.49 &  -1.62 &   2.85 &      6.83 &   2.75 & -13.97 &       -6.18 &  -1.59 &   6.67 \\
sample 14 &         -5.95 &   8.10 &  -1.43 &     10.93 &  -1.38 & -13.97 &       -6.18 &  -6.36 &  10.67 \\
sample 15 &         -5.95 & -11.34 &  15.69 &      2.73 &  11.02 & -19.96 &        3.09 &  -1.59 &  -1.33 \\
sample 16 &        -10.41 &   8.10 &   2.85 &     10.93 & -13.77 &   3.99 &       -1.54 &   7.95 &  -5.33 \\
sample 17 &        -10.41 &   3.24 &   7.13 &     10.93 &   2.75 & -19.96 &       -1.54 &  -6.36 &   6.67 \\
sample 18 &        -10.41 &  -1.62 &  11.41 &     19.14 &  -9.64 & -13.97 &      -10.81 &  12.72 &  -1.33 \\
sample 19 &        -10.41 &   3.24 &   7.13 &     15.04 &  -1.38 & -19.96 &       -6.18 &  -1.59 &   6.67 \\
sample 20 &         -5.95 &   3.24 &   2.85 &     10.93 &  -5.51 &  -7.98 &       -6.18 &   3.18 &   2.67 \\
sample 21 &        -10.41 &  -6.48 &  15.69 &      2.73 &  11.02 & -19.96 &        7.72 &  -6.36 &  -1.33 \\
sample 22 &         -1.49 &  -1.62 &   2.85 &     -5.47 &  15.15 & -13.97 &        7.72 & -15.91 &   6.67 \\
sample 23 &         -1.49 &   3.24 &  -1.43 &     10.93 &   2.75 & -19.96 &      -10.81 &  -6.36 &  14.67 \\
sample 24 &         -1.49 &  -1.62 &   2.85 &      2.73 &   2.75 &  -7.98 &       -1.54 &  -1.59 &   2.67 \\
sample 25 &         -5.95 &  12.96 &  -5.71 &     15.04 &  -1.38 & -19.96 &      -10.81 & -11.13 &  18.67 \\
sample 26 &        -10.41 &  -1.62 &  11.41 &     10.93 &  -5.51 &  -7.98 &       -1.54 &   7.95 &  -5.33 \\
sample 27 &         16.36 &  -6.48 &  -9.99 &     -1.37 &   6.89 &  -7.98 &      -15.45 &  -1.59 &  14.67 \\
sample 28 &        -14.87 &   8.10 &   7.13 &     15.04 &  -5.51 & -13.97 &       -1.54 &  -1.59 &   2.67 \\
sample 29 &        -10.41 &  -6.48 &  15.69 &      2.73 &   6.89 & -13.97 &        7.72 &  -1.59 &  -5.33 \\
sample 30 &         -5.95 &  12.96 &  -5.71 &      2.73 &  -1.38 &  -2.00 &        3.09 & -11.13 &   6.67 \\
\bottomrule
\end{tabular}
\caption{Placement results t scores}
\end{table}

\begin{table}
\begin{tabular}{lrrr}
\toprule
{} &  GuessesActive &  GuessesEx &  GuessesSamp \\
\midrule
First  &      -6.29 &       1.98 &         4.32 \\
Second &       7.97 &      -0.11 &       -11.36 \\
Third  &      -2.42 &      -1.77 &         3.61 \\
\bottomrule
\end{tabular}
\caption{t scores of placement averages}
\end{table}
