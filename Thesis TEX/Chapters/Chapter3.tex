%Chapter 3
\usepackage{amssymb}
\chapter{Overview of producable machines}
\label{Chapter3}
%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------
\section{Summary of producable machines}
The strategies mentioned in the previous section must be able to produce learning algorithms
to be considered metalearing machines. The machines that these strategies can produce are
the K-means clusterer, a neural network, a naive bayes classifier, the support vector machine,
and regression; with the results coming from the regression machine being cast into classificatory bins
from the real valued result that it would produce. An in depth description of each of these different
earning algorithms will comprise the rest of this chapter.
%--------------------------------------------------------------------------------------------
\section{Regression}
%--------------------------------------------------------------------------------------------
\section{K-Means clustering}
The objective of the k-means algorithm is to partition a dataset into
k groups such that the points within some group are all closest to
the mean of that group than they are to any other group. A clear
informal explanation of the work that the k-means algorith performs
was given by James McQueen in 1967: "...the k-means procedure
consists of simply starting with k groups each of which consists of a
single random point, and thereafter adding each new point to the
group whose mean the new point is nearest. After a point is added to
a group, the mean of that group is adjusted in order to take account
of the new point. Thus at each stage the k-means are, in fact, the
means of the groups the represent."\cite{McQueen} Formally stated, given an integer \textit{k} and a set of \textit{n} data points in $\mathbb{R}^{d}$
the K-means algorithm seeks to minimize  \Phi, the over all total summed in class distance between
each point and its closest center such that $$\mathbb\Phi = \sum_{x \in X} min_{c \in C}\left x-c \right^{2} $$
\cite{Arthur}
%--------------------------------------------------------------------------------------------
\section{Neural Networks}
A neural network is a type of machine learning algorithm that mimics
the interconnectivity of animal brains in order to automatically
discover rules to classify given inputs. Being that it is one of the most
flexible learning algorithms within literature (actually able to
approximate any continuous function)\cite{Hornik}, its inclusion within a
metalearning system is almost mandatory.  Genrally, such a system
works by first being presented with a set of classified or
unclassified inputs. Said neural network system will then attempt to
make a decision on these inputs on which an error value will then be
assigned. The system will then see some kind of correction function
applied to it. This process will continue until the system has
exhausted its supply of training data, at which point it will
hopefully have discovered a strong set of rules for peforming whatever
work it is that it was designed to perform.

The type of neural network that will be used within this thesis is
what is called the feed-forward neural network (multilayer perceptron
aka MLP). The feed forward neural network is essentially a series of
logistic regression models stacked on top of each other, with the
final layer being either another logicstic regression or linear
regression model depending on whether or not a classification or
regression problem is being solved.\cite{Murphy}. The leftmost
layer of this stack is called the input layer and consists of a set of
neurons {x_i|x_1,x_2,x_3...,x_m} representing the input's
features. Each neuron in the hidden layer transforms the values from
the previous layer via weighted linear summation w_1X_1 + w_2x_2 +
...w_mx_m \cite{Scikit} which is then passed into a non linear-action
function g(), such as the logistic function or the hyperbolic tangent
function. It is important to note that g must be non-linear, otherwise
the entire model will collapse into a large linear regression model of
the form y = w^T(Vx). \cite{Murphy}

In order to train the MLP it provides, sci-kit learn uses an error
propagation/training technique called backpropagation. Backpropagation
is a procedure that repeatedly adjusts the weights of the connections
in a neural network so as to minimize a measure of the difference
between the actual output vector of the net and the desired output
vector. \cite{Rumelhart}. In order to accomplish this, the algorithm
adjusts the weights of the nerual network by considering the error of
the outputs then minimizes this error via gradient decent with respect
to each of the weights within the network. Specifically, the gradient
vector of the negative log likelihood error on the output neurons is
computed by use of the chain rule of calculus.\cite{Murphy}.Say we
have a one layer neural network in which the hidden layer is described
by $$\alpha^{L} = \sigma(w^{L}\alpha^{L-1} + b^{L}) = \sigma(z^{L})$$
where $$L$$ superscript refers to the hidden layer and $$L-1$$ refers
to the input layer of the network. The parameters of this network can
be said to be $$\Theta = (V,W)$$ where V = weight vector for the input
layer and W is the weight vector for the hidden layer. The error (or
more specifically the costs function) of a such a network is given by $$J(\Theta ) =
- \sum_n\sum_k(\hat{y}_{nk}(\Theta)-y_{nk})^2$$ in the case of
regression and via cross entropy $$J(\Theta ) =
- \sum_n\sum_ky_{nk}log\hat{y}_{nk}(\Theta)$$ in the case of
classification. The gradient of this error $$\nabla_{\Theta}J$$ is
found via the chain rule of calculus: $$\frac{\partial C}{\partial
w^{L}} = \frac{\partial z^{L}}{\partial
w^{L}}\frac{\partial \alpha}{\partial z^{L}}\frac{\partial
C}{\partial \alpha^{L}}$$. This equation is easiest to understand if
read from right to left, notice how in each stage the rates being
compared are between nearest elements, first the error to the output
that produced it, then the output to the element to which the
non-linearity is applied, then finally the the non-linerity recieving
value to the weight vector. The result of this calculation easily
gives us the direction of the gradient, the negative of which we will
use to modify $$w^{L}$ in a direction that will reduce the output
error. Reduction of the error of a multilayer perceptron with more
than one neuron in each layer works mostly the same way. Once again,
the chain rule of calculus is used in order to find the derivative of
the output error with respect to the weights of the connections
between the hidden layer before the output neurons and the output
neurons $$\frac{\partial C}{\partial w^{L}_{n-j}}$$ where $$L$$ is the
target neurons layer (the last layer in this case), n is the index of
a neuron within this layer, and j is the index of the neuron in the
previous layer $$L-1$$ from which neuron n is recieving input (note
that in this case the hyphen does not mean subtract but rather
indicates that their is a connection between these
neurons). For an output neuron, its error is then given by $$\frac{\partial C}{\partial
w^{L}_{n-j}} = \frac{\partial z^{L}_{j}}{\partial
w^{L}_{n-j}}\frac{\partial \alpha^{L}_{j}}{\partial z^{L}_{j}}\frac{\partial
C}{\partial \alpha^{L}_{j}}$$, with the error relative to neurons
earlier in the network being calculable by continuing usage of the
chain rule. \begin{figure}\end{figure}. For an excellent and intuitive
explanation of how neural networks work, pls consider viewing the
animated overview of the method at 3Blue1Brown's youtube channel.
%--------------------------------------------------------------------------------------------
\section{Naive Bayes}
