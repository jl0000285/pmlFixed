%Chapter 3
\usepackage{amssymb}
\chapter{Overview of producable machines}
\label{Chapter3}
%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------
\section{Summary of producable machines}
The strategies mentioned in the previous section must be able to produce learning algorithms
to be considered metalearing machines. The machines that these strategies can produce are
the K-means clusterer, a neural network, a naive bayes classifier, the support vector machine,
and regression; with the results coming from the regression machine being cast into
classificatory bins from the real valued result that it would produce. An in depth
description of each of these different earning algorithms will comprise the rest of
this chapter.
%--------------------------------------------------------------------------------------------
\section{Linear Regression}
Linear regression is one of the most common and oldest machine learning techniques within
literature. It asserts that the response is a linear function of the inputs. \cite{murphy}.
This relation takes the following form:
$$ y(\textbf{x}) = \textbf{w}^T\textbf{x} + \epsilon = \sum_{j=1}^{D}w_jx_j + \epsilon $$
where $$w^Tx$$ represents the inner or scalar product between the input vector x and the
model's weight vector w^T, and \epsilon is the residual error between our linear predictions
and the true response.
To fit a linear regression model, the least squares approach is usually used. Given some
 ``overdetermined'' linear system (that is to say a system in which there are more data points
 than parameters) one can write an expression for the sum of squares of the system $$S(\beta) =
 (y_1 - \betax_1)^2 + (y_2 - \betax_2)^2 + ... (y_3 - \betax_3)$$ then take the partial deriviate
 of this sum of sqaured deviations with respect to each of the components of \beta, set them to
 zero, then solve the resulting equations to directly determine what the values of the parameters
 are that minimizes the sum of the squared errors of the system. With linear regression in two dimensions
 (one dimension in the independant variable and one dimension in the dependant variable) we see a system
 with two parameters \beta_0 = y intercept and \beta_1 = slope. If we had for example 3 data points
 (2,1),(3,7), and (4,5) we would have the equations $$\beta_0 + 2*\beta_1 = 1$$, $$\beta_0 + 3*\beta_1 = 7$$,
 and $$\beta_0 + 4*\beta_1 = 5$$. The sum of squared errors would then be
 $$S(\beta_0,\beta_1)= [1 - (\beta_0 + 2*\beta_1)]^2 + [7 - (\beta_0 + 3*\beta_1)]^2 + [5 - (\beta_0 + 4*\beta_1)]^2$$
 ,which we could then differentiate with respect to \beta_0 and \beta_1 then directly solve the resulting set
 of linear equations directly for the minimum of the summed squares.
%--------------------------------------------------------------------------------------------
\section{Naive Bayes}
%--------------------------------------------------------------------------------------------
\section{Support Vector Machine}
%--------------------------------------------------------------------------------------------
\section{K-Means clustering}
The objective of the k-means algorithm (which results in a k-means model) is to partition
a dataset into k groups such that the points within some group are all closest to
the mean of that group than they are to any other group. A clear
informal explanation of the work that the k-means algorith performs
was given by James McQueen in 1967: "...the k-means procedure
consists of simply starting with k groups each of which consists of a
single random point, and thereafter adding each new point to the
group whose mean the new point is nearest. After a point is added to
a group, the mean of that group is adjusted in order to take account
of the new point. Thus at each stage the k-means are, in fact, the
means of the groups they represent."\cite{McQueen} Formally stated,
given an integer \textit{k} and a set of \textit{n} data points in
$\mathbb{R}^{d}$ the K-means algorithm seeks to minimize  \Phi, the
over all total summed in class distance between each point and its
closest center such that $$\mathbb\Phi = \sum_{x \in X} min_{c \in C}\left x-c \right^{2} $$
\cite{Arthur}.
The k-means model is a type of gaussian mixture model that is trained with a procedure
called expectation maximization. Given a set of distributions with missing data
, mixture models tend to have derivitaves that are either difficult to define
or entirely undefinable. On the other hand, the calculation of some ML/MAP
estimates for some set of models can generally be calculated with little
difficulty if every point within the distributions is known (at which point our
learner would obviously have nothing to do) and thus calculus would be entirely
unneccessary (i.e it wouldn't matter that the derivitive cant be defined).
Expectation maximization uses this fact in order to obtain an estimation of the
ML/MAP in a roundabout way.The algorithm consists of two steps. First, an estimate as
to what the expected value of the hidden data is based off the current guess for the
parameters is made. Then the likelihood function for the parameters is maximized under
the assumption that the data discovered in the previous step is complete i.e that there
is no longer any hidden data. These steps are then repeated until some convergance criteria
is met. The k-means is exactly this type of algorithm but with the covariance matrix
\Sigma_{k} = \Rho^{2}*I_{D} and the mixing weights \Pi_{k} = 1/K all being fixed such
that the only free parameters are the cluster centers \mu_{k} \in \R^{D}
and such that the hidden data that is the ground truth label of the data points.
%--------------------------------------------------------------------------------------------
\section{Neural Networks}
A neural network is a type of machine learning algorithm that mimics
the interconnectivity of animal brains in order to automatically
discover rules to classify given inputs. Being that it is one of the most
flexible learning algorithms within literature (actually able to
approximate any continuous function)\cite{Hornik}, its inclusion within a
metalearning system is almost mandatory.  Genrally, such a system
works by first being presented with a set of classified or
unclassified inputs. Said neural network system will then attempt to
make a decision on these inputs on which an error value will then be
assigned. The system will then see some kind of correction function
applied to it. This process will continue until the system has
exhausted its supply of training data, at which point it will
hopefully have discovered a strong set of rules for peforming whatever
work it is that it was designed to perform.

The type of neural network that will be used within this thesis is
what is called the feed-forward neural network (multilayer perceptron
aka MLP). The feed forward neural network is essentially a series of
logistic regression models stacked on top of each other, with the
final layer being either another logicstic regression or linear
regression model depending on whether or not a classification or
regression problem is being solved.\cite{Murphy}. The leftmost
layer of this stack is called the input layer and consists of a set of
neurons {x_i|x_1,x_2,x_3...,x_m} representing the input's
features. Each neuron in the hidden layer transforms the values from
the previous layer via weighted linear summation w_1X_1 + w_2x_2 +
...w_mx_m \cite{Scikit} which is then passed into a non linear-action
function g(), such as the logistic function or the hyperbolic tangent
function. It is important to note that g must be non-linear, otherwise
the entire model will collapse into a large linear regression model of
the form y = w^T(Vx). \cite{Murphy}

In order to train the MLP it provides, sci-kit learn uses an error
propagation/training technique called backpropagation. Backpropagation
is a procedure that repeatedly adjusts the weights of the connections
in a neural network so as to minimize a measure of the difference
between the actual output vector of the net and the desired output
vector. \cite{Rumelhart}. In order to accomplish this, the algorithm
adjusts the weights of the nerual network by considering the error of
the outputs then minimizes this error via gradient decent with respect
to each of the weights within the network. Specifically, the gradient
vector of the negative log likelihood error on the output neurons is
computed by use of the chain rule of calculus.\cite{Murphy}.Say we
have a one layer neural network in which the hidden layer is described
by $$\alpha^{L} = \sigma(w^{L}\alpha^{L-1} + b^{L}) = \sigma(z^{L})$$
where $$L$$ superscript refers to the hidden layer and $$L-1$$ refers
to the input layer of the network. The parameters of this network can
be said to be $$\Theta = (V,W)$$ where V = weight vector for the input
layer and W is the weight vector for the hidden layer. The error (or
more specifically the costs function) of a such a network is given by $$J(\Theta ) =
- \sum_n\sum_k(\hat{y}_{nk}(\Theta)-y_{nk})^2$$ in the case of
regression and via cross entropy $$J(\Theta ) =
- \sum_n\sum_ky_{nk}log\hat{y}_{nk}(\Theta)$$ in the case of
classification. The gradient of this error $$\nabla_{\Theta}J$$ is
found via the chain rule of calculus: $$\frac{\partial C}{\partial
w^{L}} = \frac{\partial z^{L}}{\partial
w^{L}}\frac{\partial \alpha}{\partial z^{L}}\frac{\partial
C}{\partial \alpha^{L}}$$. This equation is easiest to understand if
read from right to left, notice how in each stage the rates being
compared are between nearest elements, first the error to the output
that produced it, then the output to the element to which the
non-linearity is applied, then finally the the non-linerity recieving
value to the weight vector. The result of this calculation easily
gives us the direction of the gradient, the negative of which we will
use to modify $$w^{L}$ in a direction that will reduce the output
error. Reduction of the error of a multilayer perceptron with more
than one neuron in each layer works mostly the same way. Once again,
the chain rule of calculus is used in order to find the derivative of
the output error with respect to the weights of the connections
between the hidden layer before the output neurons and the output
neurons $$\frac{\partial C}{\partial w^{L}_{n-j}}$$ where $$L$$ is the
target neurons layer (the last layer in this case), n is the index of
a neuron within this layer, and j is the index of the neuron in the
previous layer $$L-1$$ from which neuron n is recieving input (note
that in this case the hyphen does not mean subtract but rather
indicates that their is a connection between these
neurons). For an output neuron, its error is then given by $$\frac{\partial C}{\partial
w^{L}_{n-j}} = \frac{\partial z^{L}_{j}}{\partial
w^{L}_{n-j}}\frac{\partial \alpha^{L}_{j}}{\partial z^{L}_{j}}\frac{\partial
C}{\partial \alpha^{L}_{j}}$$, with the error relative to neurons
earlier in the network being calculable by continuing usage of the
chain rule. \begin{figure}\end{figure}. For an excellent and intuitive
explanation of how neural networks work, pls consider viewing the
animated overview of the method at 3Blue1Brown's youtube channel.
